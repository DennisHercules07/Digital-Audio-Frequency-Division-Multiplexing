{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0ec3a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell on Colab!\n",
    "#!pip install control==0.9.0 import-ipynb==0.1.3 joblib==1.1.0 simpleaudio==1.0.4 soundfile==0.10.3.post1 threadpoolctl==3.0.0 &> /dev/null\n",
    "\n",
    "# if you run this locally on Jupyter notebook, run the following command in your Anaconda terminal (without the #)\n",
    "# pip install control==0.9.0 import-ipynb==0.1.3 joblib==1.1.0 simpleaudio==1.0.4 soundfile==0.10.3.post1 threadpoolctl==3.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e209c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import soundfile as sf\n",
    "import scipy.signal as ss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import import_ipynb\n",
    "from audio_read import audio_read\n",
    "from mux import mux\n",
    "from demux import demux\n",
    "from audio_save import audio_save\n",
    "from play_buffer_wrapper import play_buffer_wrapper\n",
    "from upconverter import upconverter\n",
    "from downconverter import downconverter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d45c594",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "In telecommunication systems, multiplexing is a technique that allows multiple signals to be transmitted simultaneously, avoiding interference among different channels. One method for multiplexing is Frequency Division Multiplexing (FDM), which will be analyzed in this exercise.\n",
    "\n",
    "Before diving into how it works, a couple of definitions are necessary:\n",
    "\n",
    "**Baseband bandlimited** : the DFT of the signal $x[n]$ with bandwidth $f_{bw}$ is $X(f) = 0, \\ \\forall |{f}|>f_{bw}$. \n",
    "\n",
    "**Passband** : the energy of the signal $x[n]$ is distributed through the frequencies $f\\in[f_1,f_2]$ where $f_1<f_2,\\ f_1> 0$ and $f_2<f_s/2$. In other words $\\forall f\\notin[f_1,f_2]$ we have $X(f)=0$. Such a passband signal has bandwidth $f_{bw}=(f_2-f_1)/2$\n",
    "\n",
    "Please note that in this homework we work with DFT coefficients expressed as frequencies $f$ in Hertz (similar to Homework 3). The discrete-time angular frequency $\\Omega_k = \\frac{2\\pi k}{N}$ is associated with the continuous-time frequency $f$ via the following relationships: $f = \\frac{\\Omega_k}{2\\pi T_s} = \\frac{\\Omega_k}{2\\pi}f_s$ and $\\Omega_k = 2\\pi f T_s = 2\\pi \\frac{f}{f_s}$. Alternatively, you can also use the relationship $f = \\frac{k}{NT_s}$, where $k$ is the index of $\\Omega_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86f09f8",
   "metadata": {},
   "source": [
    "<b>Task 1.</b> \n",
    "\n",
    "The idea of multiplexing is to simultaneously transmit $N$ baseband bandlimited signals, $\\{y_i[n]\\}_{i\\in[N]}$ with bandwidth $f_{bw}$ without interference by exploiting the orthogonality of non-overlapping frequency bands. The following steps are carried out to achieve this: \n",
    "\n",
    "1. Each of the N signals is first *upconverted* to a carrier frequency $f_{c_i}$. *Upconversion* is the operation that shifts a signal to the right in the frequency domain, in this case from a baseband to a passband signal. Mathematically, let $Y_i(f)$ be the DFT of the baseband signal $y_i[n]$ and $Y_i^u(f)$ the DFT of the baseband signal upconverted to the carrier frequency $f_{c_i}$. Then the following relationship holds: $Y_i^u(f) = Y_i(f-f_{c_i})$. We exploit this property for every $\\{y_i[n]\\}_{i\\in[N]}$.\n",
    "\n",
    "2. The resulting upconverted signal $y^u_i[n]$ is  passband and complex. Since we cannot transmit imaginary signals, usually the real part of the upconverted signal is kept, giving $\\hat{y}_i[n] = \\alpha \\operatorname{Re}\\{y^u_i[n]\\}$. The coefficient $\\alpha$ ensures that the energies of $\\hat{y}_i$ and $y_i$ remain the same.\n",
    "\n",
    "3. The last step of FDM is to sum up the $\\{\\hat{y}_i[n]\\}_{i\\in[N]}$ signals and transmit the sum.\n",
    "\n",
    "    \n",
    "<b>(a)</b> Why are audio files usually sampled at 44.1kHz? For a signal of bandwidth $f_{bw}$ and a sample rate $f_s$, what is the maximum carrier frequency to which one could upconvert? What happens if you go beyond this carrier frequency? \n",
    "\n",
    "<b>(b)</b> Define the mathematical relationship, in the time domain, between the baseband signal $y_i[n]$ and the real passband signal $\\hat{y}_i[n]$. Refer to the upconversion description in the introduction.\n",
    "\n",
    "*Hint* : Start from $Y_i^u(f) = Y_i(f-f_{c_i})$ and derive an equivalent expression in the time domain\n",
    "\n",
    "<b>(c)</b> Using your analytical result from (b), implement the **upconverter** function. Your function takes as an input argument the length of the signal which will be upconverted, i.e. the length of $y_i[n]$. The output of this function can be directly multiplied with the time domain audio signal to obtain the upconverted signal $y^u_i[n]$.\n",
    "\n",
    "*Note*: Use the code in the following cell to test your implementation. You don't need to modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a92f0e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661871"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Read audio file\n",
    "audio, Fs= audio_read('audio/original/champions.wav')\n",
    "index= 0\n",
    "L= len(audio)\n",
    "\n",
    "# Bandwidth frequency\n",
    "F_bw= 3.7e3\n",
    "\n",
    "# Upconversion\n",
    "up= upconverter(index, L, Fs, F_bw)\n",
    "y_up= (up*audio)\n",
    "y_up.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f1d160",
   "metadata": {},
   "source": [
    "<b>(d)</b> Using your **upconverter**, implement the **mux** function, with carrier frequency $f_{c_i} = (2i+1)f_{mux,bw}$ and $f_{mux,bw} = 3.7$ kHz. We denote $i=0,1,2...$ as the index of the audio file the upconverter is for.\n",
    "\n",
    "*Hint*: First, compute a different upconverter for each audio file $i$, then use your upconverters to compute $y^u_i[n]$ and finally sum over all of your indexes (step 3 for the FDM).\n",
    "\n",
    "*Note*: Use the code in the following cell to test your implementation. Do not modify it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c93ee115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reading audio files\n",
    "audio1, Fs = audio_read('audio/original/champions.wav')                   #Audio file 1\n",
    "audio2, Fs = audio_read('audio/original/iphone.wav')                      #Audio file 2\n",
    "audio3, Fs = audio_read('audio/original/the_polish_ambassador.wav')       #Audio file 3\n",
    "\n",
    "L= len(audio3)                                                            # length of audio file 3\n",
    "\n",
    "F_bw = 3.7e3                                                              # Bandwidth frequency\n",
    "\n",
    "max_len = max(len(audio1), len(audio2), len(audio3))                      # Selecting file with the highest length\n",
    "y1_padded = np.pad(audio1, (0, max_len - len(audio1)))\n",
    "y2_padded = np.pad(audio2, (0, max_len - len(audio2)))\n",
    "y3_padded = np.pad(audio3, (0, max_len - len(audio3)))\n",
    "\n",
    "y_list = [y1_padded, y2_padded, y3_padded]                                # creating list of audio signals\n",
    "mux_signal = mux(y_list, Fs, F_bw,L)                                      # Multiplexing of signals Proceeds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933fd8dd",
   "metadata": {},
   "source": [
    "<b>(e)</b> Using **mux**, read the 3 audio files provided in *audio/original/* and generate a multiplexed **mux_signal** and save it as *mux.wav*. \n",
    "\n",
    "*Hint* : This is just an extension of the code provided in the previous cell. Use the provided functions **audio_read**, **audio_save** and **play_buffer_wrapper**.\n",
    "\n",
    "*Note* : We do not provide you a code template for this question, implement your solution in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a26c4a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#muxing\n",
    "mux_signal /= np.max(np.abs(mux_signal))\n",
    "audio_save('saved_track/mux1_1.wav', mux_signal, Fs)   # saving final multiplexed signal as mux1_1.wav file in saved_track folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ccc247",
   "metadata": {},
   "source": [
    "<b>Task 2.</b> \n",
    "\n",
    "Demultiplexing is the inverse operation of multiplexing. Given a multiplexed signal, this operation restores the $N$ original baseband signals. This is done by *downconverting* the multiplexed signal $N$ times with carrier frequencies $\\{f_{c_i}\\}_{i\\in[N]}$. *Downconversion*, like upconversion, also shifts a signal in the frequency domain, except that it shifts to the left instead of to the right. Then, these $N$ downconverted signals are each passed through a lowpass filter with cutoff frequency $f_{p} = f_{mux,bw} =  f_{c_1}$ (called the multiplexing bandwidth) to obtain the $N$ original signals. Keep in mind that the energies of the resulting signals should be the same as the original, so there will be a normalizing coefficient here too. In terms of real world applications: most wireless communication systems use this technique to communicate without interference. As a result one cannot transmit at any randomly chosen carrier frequency as this will possibly interfere with another transmission. Each country has a frequency allocation plan that must be respected. If you look at one of these frequency allocation plans, it is impressive to see how many different communication systems are transmitting at the same time and to consider that this technique allows them not to interfere with one another.\n",
    "\n",
    "<b>(a)</b> Rewrite the relationship that you derived in Task 1 (b) and implement the **downconverter** function that reverses the *Upconversion*.\n",
    "\n",
    "*Note*: Use the code in the following cell to test your implementation. You don't need to modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73eb6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reading audio file\n",
    "audio, Fs = audio_read('audio/original/champions.wav')\n",
    "L=len(audio)\n",
    "\n",
    "# Bandwidth frequency\n",
    "F_bw=3.7e3\n",
    "\n",
    "# Column of the desired audio channel\n",
    "index=0\n",
    "\n",
    "# Downconversion using the downconverter function\n",
    "down= downconverter(index, L, Fs, F_bw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7909dd",
   "metadata": {},
   "source": [
    "<b>(b)</b> Using your **downconverter**, implement the **demux** function that is able to restore the original audio signals contained in the mux. Your function takes the number of original audio signals in the mux as an input argument **audio_col**. This needs to be known beforehand.\n",
    "\n",
    "*Hint*: Similar to the **mux** function, you can apply your **demux** to the **mux_signal** in order to obtain the downconverted signals. Don't forget to filter the downconverted signals. You want to pass the $N$ downconverted signals through a lowpass filter with cutoff frequency $f_{p} = f_{mux,bw} =  f_{c_1}$ to obtain the $N$ original signals (use one of the Python native filters to do that). The output **demux_signal** should have one column for each of the original audio signals. \n",
    "\n",
    "*Note* : We do not provide you a code template for this question, implement your solution in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dba2e766",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3700.0\n",
      "44100\n",
      "[[-0.49497157 -0.49490078 -0.49144634]\n",
      " [-0.31365313 -0.2968559  -0.39715407]\n",
      " [-0.16479348 -0.13570538 -0.32119604]\n",
      " ...\n",
      " [-0.42953236 -0.2843778  -1.03071525]\n",
      " [-0.82642925 -0.67693385 -0.90373513]\n",
      " [-1.30837347 -1.14297509 -0.79794595]]\n"
     ]
    }
   ],
   "source": [
    "#demuxing phase\n",
    "\n",
    "demux_filtered = demux(mux_signal,Fs,3,F_bw,1,2)\n",
    "demux_filtered\n",
    "\n",
    "#printing to show value of the bandwith frequency, sampling frquency and the demuxed filtered\n",
    "print(f'{F_bw}')\n",
    "print(f'{Fs}')\n",
    "print(f'{demux_filtered}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0434bbd8",
   "metadata": {},
   "source": [
    "<b>(c)</b> Using your **demux**, you can demultiplex the previously generated *mux.wav* audio file. You should be able to restore audio signals that are almost like the original audio files. Save the resulting audio file as *demux_i.wav*, where i corresponds to the index of the restored audio.\n",
    "\n",
    "*Hint* : Use the DFT to determine $f_{bw}$, the bandwidth, $N$, the number of multiplexed signals, and the different $\\{f_{c_i}\\}_{i\\in[N]}$.\n",
    "\n",
    "*Note* : We do not provide you a code template for this question, implement your solution in the cells below. If you did not succeed in implementing the filtering functions, you may use the native Python functions. If you did not manage to generate the *mux.wav* in the previous task you may use the *mux_sample.wav*, which contains 5 audio signals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e67fd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Song1_1 = demux_filtered[0:, 0]\n",
    "Song2_2 = demux_filtered[0:, -2]\n",
    "Song3_3 = demux_filtered[0:, -1]\n",
    "\n",
    "song1_1 = Song1_1[:661872]\n",
    "song2_2 = Song2_2[:661872]\n",
    "\n",
    "#song1_1, song2_2 and song3_3 saved as demux1_1, demux2_2 and demux3_3 in the saved_track folder\n",
    "song1 = audio_save('saved_track/demux1_1.wav', song1_1, Fs)      \n",
    "song2 = audio_save('saved_track/demux2_2.wav', song2_2, Fs)\n",
    "song3  =audio_save('saved_track/demux3_3.wav', Song3_3, Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba146c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a49be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d300c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39587b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc436c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d7a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93102da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
